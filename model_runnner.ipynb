{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqGZuHED+P0qiEERTfVxo2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InukshiSenarathne/chatbot_colab_testing/blob/main/model_runnner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "710K1EjWR6Qa",
        "outputId": "b48534c4-5401-49a6-aea3-2483414a6679"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT ANALYZER"
      ],
      "metadata": {
        "id": "4vcTSzF9RuvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "id": "95XXHzX1SRFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "def predict_emotion(text, model_path, class_names):\n",
        "    # Load the tokenizer associated with the model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Load the model\n",
        "    loaded_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    # Make predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get the predicted class (assuming it's a classification model)\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Get the emotion label name\n",
        "    predicted_label = class_names[predicted_class]\n",
        "\n",
        "    # Get the confidence score (softmax probability) and round it to two decimal points\n",
        "    confidence_score = round(torch.softmax(logits, dim=1)[0][predicted_class].item()*100, 2)\n",
        "\n",
        "    return predicted_label, confidence_score"
      ],
      "metadata": {
        "id": "vhSZUquhRt9Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDjoLEpnRq8U",
        "outputId": "2c32ac65-7e67-42e3-80a7-d33a072971e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: sadness, Predicted accuracy: 98.06%\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "model_path = \"/content/drive/MyDrive/research_project_y4_sliit/models/finalized_models/text\"  # Replace with the actual path to your saved model\n",
        "class_names = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
        "text = \"i'm disappointed with my career\"\n",
        "\n",
        "predicted_label, confidence_score = predict_emotion(text, model_path, class_names)\n",
        "# Print the predicted label and confidence score\n",
        "print(f\"Predicted Emotion: {predicted_label}, Predicted accuracy: {confidence_score}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "scX8g-43Sru4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT ANALYZER"
      ],
      "metadata": {
        "id": "eIkHQxEpSrCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy librosa matplotlib pydub tensorflow scikit-learn seaborn\n",
        "!pip install moviepy pydub"
      ],
      "metadata": {
        "id": "3Rpn9m8YSqgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "from pydub import AudioSegment, effects\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import load_model\n",
        "import moviepy.editor as mp\n",
        "from pydub import AudioSegment\n",
        "\n",
        "FRAME_LENGTH = 2048\n",
        "HOP_LENGTH = 512\n",
        "MODEL_PATH = \"/content/drive/MyDrive/research_project_y4_sliit/models/finalized_models/voice/voice.h5\"\n",
        "\n",
        "def preprocess_audio(path):\n",
        "    _, sr = librosa.load(path)\n",
        "    raw_audio = AudioSegment.from_file(path)\n",
        "\n",
        "    samples = np.array(raw_audio.get_array_of_samples(), dtype='float32')\n",
        "    trimmed, _ = librosa.effects.trim(samples, top_db=25)\n",
        "    padded = np.pad(trimmed, (0, 180000 - len(trimmed)), 'constant')\n",
        "    return padded, sr\n",
        "\n",
        "def test_single_audio(audio_path):\n",
        "    model = load_model(MODEL_PATH)\n",
        "    y, sr = preprocess_audio(audio_path)\n",
        "\n",
        "    zcr = librosa.feature.zero_crossing_rate(y, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
        "    rms = librosa.feature.rms(y=y, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=HOP_LENGTH)\n",
        "\n",
        "    # Ensure that all feature arrays have the same shape\n",
        "    max_len = min(zcr.shape[1], rms.shape[1], mfccs.shape[1])\n",
        "    zcr = zcr[:, :max_len]\n",
        "    rms = rms[:, :max_len]\n",
        "    mfccs = mfccs[:, :max_len]\n",
        "\n",
        "    X_test = np.concatenate((zcr, rms, mfccs), axis=0)  # Concatenate along axis 0\n",
        "    X_test = X_test.T  # Transpose to match the shape\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    y_pred = model.predict(np.expand_dims(X_test, axis=0))\n",
        "    # print(y_pred)\n",
        "    emotion_labels = ['neutral', 'happy', 'sad', 'angry', 'fear', 'disgust']\n",
        "    predicted_emotion = emotion_labels[np.argmax(y_pred)]\n",
        "    accuracy = np.amax(y_pred)*100\n",
        "\n",
        "    print(f\"Predicted Emotion: {predicted_emotion}, Predicted accuracy: {round(accuracy, 2)}%\")\n"
      ],
      "metadata": {
        "id": "3wR_HIlaSnvd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_single_audio(\"/content/drive/MyDrive/research_project_y4_sliit/voice_meeting_clips/OAF_happy/OAF_bean_happy.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXhXLndETn5J",
        "outputId": "7a4423ec-2976-40cf-eeca-477d66064eac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted Emotion: happy, Predicted accuracy: 99.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "zGl_ps8_T70L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FACE ANALYZER"
      ],
      "metadata": {
        "id": "1h1XtVUAUBzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cv2 keras.models matplotlib.pyplot numpy"
      ],
      "metadata": {
        "id": "FTLyA5WUX6JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv2\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "classes = ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
        "\n",
        "# load model and and use\n",
        "def test_img(img):\n",
        "  model_path = '/content/drive/MyDrive/research_project_y4_sliit/models/finalized_models/face/face_model_c01.h5'\n",
        "  model = load_model(model_path)\n",
        "  img_size = (224, 224)\n",
        "  fpath=img\n",
        "  img=plt.imread(fpath)\n",
        "  print ('Input image shape is ', img.shape)\n",
        "  # resize the image so it is the same size as the images the model was trained on\n",
        "  img=cv2.resize(img, img_size) # in earlier code img_size=(224,224) was used for training the model\n",
        "  print ('the resized image has shape ', img.shape)\n",
        "  ### show the resized image\n",
        "  # plt.imshow(img)\n",
        "  # Normally the next line of code rescales the images. However the EfficientNet model expects images in the range 0 to 255\n",
        "  # plt.imread returns a numpy array so it is not necessary to convert the image to a numpy array\n",
        "  # since we have only one image we have to expand the dimensions of img so it is off the form (1,224,224,3)\n",
        "  # where the first dimension 1 is the batch size used by model.predict\n",
        "  img=np.expand_dims(img, axis=0)\n",
        "  print ('image shape after expanding dimensions is ',img.shape)\n",
        "  # now predict the image\n",
        "  pred=model.predict(img)\n",
        "  print (' the shape of prediction is ', pred.shape)\n",
        "  # this dataset has 15 classes so model.predict will return a list of 15 probability values\n",
        "  # we want to find the index of the column that has the highest probability\n",
        "  index=np.argmax(pred[0])\n",
        "  # to get the actual Name of the class earlier Imade a list of the class names called classes\n",
        "  klass=classes[index]\n",
        "\n",
        "  # lets get the value of the highest probability\n",
        "  probability = pred[0][index] * 100\n",
        "  if probability < 30:\n",
        "      print(\"Try again.\")\n",
        "  else:\n",
        "      # Print out the class and the probability.\n",
        "      print('The image is predicted as being', klass, 'with a probability of', probability)"
      ],
      "metadata": {
        "id": "XEnto6E5UbY7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img('/content/drive/MyDrive/research_project_y4_sliit/facial_expressions/test03.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS87Z0z5UfTq",
        "outputId": "d4565184-03b4-44f1-c231-b82d041e21e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image shape is  (137, 110, 3)\n",
            "the resized image has shape  (224, 224, 3)\n",
            "image shape after expanding dimensions is  (1, 224, 224, 3)\n",
            "1/1 [==============================] - 2s 2s/step\n",
            " the shape of prediction is  (1, 7)\n",
            "The image is predicted as being sad with a probability of 58.27180743217468\n"
          ]
        }
      ]
    }
  ]
}